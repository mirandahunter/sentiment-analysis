{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-25 11:07:03.658538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /Users/wjones/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers # HuggingFace!\n",
    "from transformers import AutoTokenizer # a librabry that has tokenizers for all of the different models\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "#import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch_pretrained_bert\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "BERT_CLASS = AutoModelForSequenceClassification\n",
    "\n",
    "# Make sure all the files are in same folder, i.e vocab , config and bin file\n",
    "PRE_TRAINED_MODEL_NAME_OR_PATH = '/path/to/the/files/containing/models/files'\n",
    "\n",
    "model = BERT_CLASS.from_pretrained('ert.pth', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "#Read a comma-separated values (csv) file into DataFrame\n",
    "path = \"clean_IMDBdataset.csv\"\n",
    "df = pd.read_csv(path, sep=\",\")\n",
    "#This changes all of the Y labels to be 0s or 1s\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(df, df, test_size=0.2, random_state=30)\n",
    "\n",
    "X_test,X_valid,Y_test, Y_valid = train_test_split(X_test, Y_test, test_size=0.5, random_state=30)\n",
    "\n",
    "X_tr_dataset = Dataset.from_pandas(X_train)\n",
    "X_test_dataset = Dataset.from_pandas(X_test)\n",
    "X_v_dataset = Dataset.from_pandas(X_valid)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Phrase\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# Tokenizes the data\n",
    "tokenizedX_train = X_tr_dataset.map(tokenize_function, batched=True)\n",
    "tokenizedX_test = X_test_dataset.map(tokenize_function, batched=True)\n",
    "tokenizedX_valid = X_v_dataset.map(tokenize_function, batched=True)\n",
    "# Remove the column with the actual reviews (as opposed to the review ids) because the model does not accept raw text as an input!\n",
    "tokenizedX_trainE = tokenizedX_train.remove_columns([\"Phrase\"])\n",
    "tokenizedX_testE = tokenizedX_test.remove_columns([\"Phrase\"])\n",
    "tokenizedX_validE = tokenizedX_valid.remove_columns([\"Phrase\"])\n",
    "\n",
    "# Removes another unnecesary column\n",
    "tokenizedX_trainE = tokenizedX_trainE.remove_columns([\"__index_level_0__\"])\n",
    "tokenizedX_testE = tokenizedX_testE.remove_columns([\"__index_level_0__\"])\n",
    "tokenizedX_validE = tokenizedX_validE.remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "\n",
    "# Makes sure the columns are titled in the way that the model expects\n",
    "tokenizedX_trainf = tokenizedX_trainE.rename_column(\"Sentiment\", \"labels\")\n",
    "tokenizedX_testf = tokenizedX_testE.rename_column(\"Sentiment\", \"labels\")\n",
    "tokenizedX_validf = tokenizedX_validE.rename_column(\"Sentiment\", \"labels\")\n",
    "\n",
    "\n",
    "\n",
    "# Sets the format of the dataset to return PyTorch tensors instead of lists\n",
    "tokenizedX_trainf.set_format(\"torch\")\n",
    "tokenizedX_testf.set_format(\"torch\")\n",
    "tokenizedX_validf.set_format(\"torch\")\n",
    "# You might need to create a smaller subset of the dataset if it's going really slow\n",
    "\n",
    "train_dataloader = DataLoader(tokenizedX_trainf, shuffle=True, batch_size=8)\n",
    "# I don't want the eval DataLoader to be my validation, right?\n",
    "valid_dataloader = DataLoader(tokenizedX_validf, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in valid_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
