{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/LizzieBlaschke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers # HuggingFace!\n",
    "from transformers import AutoTokenizer # a librabry that has tokenizers for all of the different models\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "#import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = \"clean_IMDBdataset.csv\"\n",
    "df = pd.read_csv(path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a comma-separated values (csv) file into DataFrame\n",
    "path = \"clean_IMDBdataset.csv\"\n",
    "df = pd.read_csv(path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This changes all of the Y labels to be 0s or 1s\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710cc638a3d14fc9bd9e418a726d3d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f90102e0e6742fa8b9db45932fcff81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9d976d44d84ab8b776080e3173702c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(df, df, test_size=0.2, random_state=30)\n",
    "\n",
    "X_test,X_valid,Y_test, Y_valid = train_test_split(X_test, Y_test, test_size=0.5, random_state=30)\n",
    "\n",
    "X_tr_dataset = Dataset.from_pandas(X_train)\n",
    "X_test_dataset = Dataset.from_pandas(X_test)\n",
    "X_v_dataset = Dataset.from_pandas(X_valid)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Phrase\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# Tokenizes the data\n",
    "tokenizedX_train = X_tr_dataset.map(tokenize_function, batched=True)\n",
    "tokenizedX_test = X_test_dataset.map(tokenize_function, batched=True)\n",
    "tokenizedX_valid = X_v_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# Remove the column with the actual reviews (as opposed to the review ids) because the model does not accept raw text as an input!\n",
    "tokenizedX_trainE = tokenizedX_train.remove_columns([\"Phrase\"])\n",
    "tokenizedX_testE = tokenizedX_test.remove_columns([\"Phrase\"])\n",
    "tokenizedX_validE = tokenizedX_valid.remove_columns([\"Phrase\"])\n",
    "\n",
    "# Removes another unnecesary column\n",
    "tokenizedX_trainE = tokenizedX_trainE.remove_columns([\"__index_level_0__\"])\n",
    "tokenizedX_testE = tokenizedX_testE.remove_columns([\"__index_level_0__\"])\n",
    "tokenizedX_validE = tokenizedX_validE.remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "\n",
    "# Makes sure the columns are titled in the way that the model expects\n",
    "tokenizedX_trainf = tokenizedX_trainE.rename_column(\"Sentiment\", \"labels\")\n",
    "tokenizedX_testf = tokenizedX_testE.rename_column(\"Sentiment\", \"labels\")\n",
    "tokenizedX_validf = tokenizedX_validE.rename_column(\"Sentiment\", \"labels\")\n",
    "\n",
    "\n",
    "\n",
    "# Sets the format of the dataset to return PyTorch tensors instead of lists\n",
    "tokenizedX_trainf.set_format(\"torch\")\n",
    "tokenizedX_testf.set_format(\"torch\")\n",
    "tokenizedX_validf.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to create a smaller subset of the dataset if it's going really slow\n",
    "\n",
    "train_dataloader = DataLoader(tokenizedX_trainf, shuffle=True, batch_size=8)\n",
    "# I don't want the eval DataLoader to be my validation, right?\n",
    "valid_dataloader = DataLoader(tokenizedX_validf, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading the model with the expected number of labels, for the IMDb dataset, there are two different labels, 0 or 1!\n",
    "# Maybe I could try loading bert-base-cased too?\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the optimizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optim = AdamW(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "# Can adjust this is it's not quite right...\n",
    "num_epochs = 3\n",
    "num_train_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name = \"linear\", optimizer = optim, num_warmup_steps = 0, num_training_steps = num_train_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_train_steps))\n",
    "\n",
    "model.train()\n",
    "for ep in range(num_epochs):\n",
    "  for batch in train_dataloader:\n",
    "    #print(batch.keys())\n",
    "    #for k in batch:\n",
    "      #print(k, batch[k]) \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss.backward\n",
    "\n",
    "    optim.step()\n",
    "    lr_scheduler.step()\n",
    "    optim.zero_grad()\n",
    "    progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
