{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/wjones/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/r024mm7x74qd70l_5q2qs0hm0000gn/T/ipykernel_80445/3302568041.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Phrase'] = df['Phrase'].str.replace(r'[^\\w\\s]+', '')\n",
      "/var/folders/01/r024mm7x74qd70l_5q2qs0hm0000gn/T/ipykernel_80445/3302568041.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Phrase'] = df['Phrase'].str.replace(r'\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "path = \"RottenTomatoes/DataSet/train.tsv\"\n",
    "df = pd.read_csv(path, sep=\"\\t\") \n",
    "\n",
    "# remove punctuation\n",
    "df['Phrase'] = df['Phrase'].str.replace(r'[^\\w\\s]+', '')\n",
    "# remove numbers\n",
    "df['Phrase'] = df['Phrase'].str.replace(r'\\d+', '')\n",
    "# make it all lower case\n",
    "df['Phrase'] = df['Phrase'].str.lower()\n",
    "# remove non-asci characters\n",
    "df.Phrase.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "#df['Phrase'] = df['Phrase'].str.split()\n",
    "\n",
    "df['Tokenized_text'] = df['Phrase'].apply(word_tokenize) \n",
    "\n",
    "df['Sentiment']=df['Sentiment'].astype(int) #convert the star_rating column to int\n",
    "df['NNLabels'] = df['Sentiment'].div(4)\n",
    "\n",
    "df= df[df['Sentiment']!=2]\n",
    "\n",
    "#df['label']=np.where(df['Sentiment']>=4,1,0) #1-Positve,0-Negative\n",
    "# convert to NumPy Array\n",
    "train = df['Phrase'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (61182,) (61182,) Test:  ((15296,), (15296,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(df['Phrase'], df['Sentiment'], test_size=0.2, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (30591,) (30591,) Test:  ((30591,), (30591,))\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,Y_train, Y_valid = train_test_split(X_train,Y_train, test_size=0.5, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_valid.shape,Y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "tf_x_train = tfidfvectorizer.fit_transform(X_train)\n",
    "tf_x_valid = tfidfvectorizer.transform(X_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC\n",
    "- This is a model that draws hyperplanes to cluster the data. It is aware of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.4579002079002079,\n",
       "  'recall': 0.30944854232525465,\n",
       "  'f1-score': 0.36931460909662545,\n",
       "  'support': 2847},\n",
       " '1': {'precision': 0.690320874471086,\n",
       "  'recall': 0.7175845322092916,\n",
       "  'f1-score': 0.7036887271420227,\n",
       "  'support': 10913},\n",
       " '3': {'precision': 0.6874407261888633,\n",
       "  'recall': 0.7746564885496183,\n",
       "  'f1-score': 0.7284473476419496,\n",
       "  'support': 13100},\n",
       " '4': {'precision': 0.5048809058961343,\n",
       "  'recall': 0.346555883141249,\n",
       "  'f1-score': 0.41099809281627464,\n",
       "  'support': 3731},\n",
       " 'accuracy': 0.6587885325749403,\n",
       " 'macro avg': {'precision': 0.5851356786140729,\n",
       "  'recall': 0.5370613615563534,\n",
       "  'f1-score': 0.5531121941742181,\n",
       "  'support': 30591},\n",
       " 'weighted avg': {'precision': 0.6448399126529842,\n",
       "  'recall': 0.6587885325749403,\n",
       "  'f1-score': 0.6474743522541285,\n",
       "  'support': 30591}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(tf_x_train,Y_train)\n",
    "y_test_pred=clf.predict(tf_x_valid)\n",
    "\n",
    "report=classification_report(Y_valid, y_test_pred,output_dict=True)\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on Rotton Tomatoes:\n",
    "- As we see, this has a nearly 65% accuracy on the subjectivity dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the input is a 4 out of 4\n"
     ]
    }
   ],
   "source": [
    "sentance = [\"This is the absolute best thing ever\"] # put your sentance here, it will predict the sentiment\n",
    "sent = tfidfvectorizer.transform(sentance)\n",
    "sent_prediction = clf.predict(sent)\n",
    "print(\"The sentiment of the input is a \" + sent_prediction[0].astype(str)+\" out of 4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/wjones/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "path = \"clean_IMDBdataset.csv\"\n",
    "df = pd.read_csv(path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (40000,) (40000,) Test/Valid:  ((10000,), (10000,))\n",
      "Test:  (5000,) (5000,) Valid:  ((5000,), (5000,))\n"
     ]
    }
   ],
   "source": [
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(df['Phrase'], df['Sentiment'], test_size=0.2, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test/Valid: \",(X_test.shape,Y_test.shape))\n",
    "X_test,X_valid,Y_test, Y_valid = train_test_split(X_test,Y_test, test_size=0.5, random_state=30)\n",
    "print(\"Test: \" ,X_test.shape,Y_test.shape,\"Valid: \",(X_valid.shape,Y_valid.shape))\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "tf_x_train = tfidfvectorizer.fit_transform(X_train)\n",
    "tf_x_valid = tfidfvectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 185967)\n"
     ]
    }
   ],
   "source": [
    "print(tf_x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, ..., 1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred=clf.predict(tf_x_valid[:,:14320])\n",
    "y_test_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[y_test_pred <= 2] = 0\n",
    "y_test_pred[y_test_pred > 2] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.46086261980830673,\n",
       "  'recall': 0.22988047808764941,\n",
       "  'f1-score': 0.3067517278043594,\n",
       "  'support': 2510},\n",
       " '1': {'precision': 0.4842582710779082,\n",
       "  'recall': 0.7289156626506024,\n",
       "  'f1-score': 0.5819172811798653,\n",
       "  'support': 2490},\n",
       " 'accuracy': 0.4784,\n",
       " 'macro avg': {'precision': 0.4725604454431075,\n",
       "  'recall': 0.4793980703691259,\n",
       "  'f1-score': 0.4443345044921123,\n",
       "  'support': 5000},\n",
       " 'weighted avg': {'precision': 0.4725136541405683,\n",
       "  'recall': 0.4784,\n",
       "  'f1-score': 0.44378417338536136,\n",
       "  'support': 5000}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(Y_valid, y_test_pred,output_dict=True)\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "- I was suprised that cross testing did not generate similar results, but I chalk it up to the differences in the datasets -- the rotten tomatoes included many more words and terms, where as the IMBD dataset was long phrases. I also had to remove a lot of features from the IMBD dataset to make it compadible with the original dataset. \n",
    "- I believe that training on both datasets would potentially generate better results. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on IMBD dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9147254575707154,\n",
       "  'recall': 0.8760956175298805,\n",
       "  'f1-score': 0.894993894993895,\n",
       "  'support': 2510},\n",
       " '1': {'precision': 0.8802003081664098,\n",
       "  'recall': 0.9176706827309237,\n",
       "  'f1-score': 0.8985450255603618,\n",
       "  'support': 2490},\n",
       " 'accuracy': 0.8968,\n",
       " 'macro avg': {'precision': 0.8974628828685627,\n",
       "  'recall': 0.8968831501304021,\n",
       "  'f1-score': 0.8967694602771283,\n",
       "  'support': 5000},\n",
       " 'weighted avg': {'precision': 0.8975319331673712,\n",
       "  'recall': 0.8968,\n",
       "  'f1-score': 0.8967623580159955,\n",
       "  'support': 5000}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LinearSVC(random_state=0)\n",
    "clf2.fit(tf_x_train,Y_train)\n",
    "y_test_pred2=clf2.predict(tf_x_valid)\n",
    "\n",
    "report=classification_report(Y_valid, y_test_pred2,output_dict=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7578558225508318,\n",
       "  'recall': 0.6533864541832669,\n",
       "  'f1-score': 0.7017543859649122,\n",
       "  'support': 2510},\n",
       " '1': {'precision': 0.6932299012693935,\n",
       "  'recall': 0.7895582329317269,\n",
       "  'f1-score': 0.7382651145324821,\n",
       "  'support': 2490},\n",
       " 'accuracy': 0.7212,\n",
       " 'macro avg': {'precision': 0.7255428619101127,\n",
       "  'recall': 0.7214723435574969,\n",
       "  'f1-score': 0.7200097502486972,\n",
       "  'support': 5000},\n",
       " 'weighted avg': {'precision': 0.7256721137526756,\n",
       "  'recall': 0.7212,\n",
       "  'f1-score': 0.719936728791562,\n",
       "  'support': 5000}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LinearSVC(random_state=0)\n",
    "clf1.fit(tf_x_train[:,:14320],Y_train)\n",
    "y_test_pred1=clf1.predict(tf_x_valid[:,:14320])\n",
    "\n",
    "report=classification_report(Y_valid, y_test_pred1,output_dict=True)\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "- as we can see here, this is really good at polarity predicitions. That makes sense, as it only has to draw one \"hyperplane\" and there is likley a strong line that can be drawn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Testing on Rotten Tomatoes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/r024mm7x74qd70l_5q2qs0hm0000gn/T/ipykernel_80445/3302568041.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Phrase'] = df['Phrase'].str.replace(r'[^\\w\\s]+', '')\n",
      "/var/folders/01/r024mm7x74qd70l_5q2qs0hm0000gn/T/ipykernel_80445/3302568041.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Phrase'] = df['Phrase'].str.replace(r'\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "path = \"RottenTomatoes/DataSet/train.tsv\"\n",
    "df = pd.read_csv(path, sep=\"\\t\") \n",
    "\n",
    "# remove punctuation\n",
    "df['Phrase'] = df['Phrase'].str.replace(r'[^\\w\\s]+', '')\n",
    "# remove numbers\n",
    "df['Phrase'] = df['Phrase'].str.replace(r'\\d+', '')\n",
    "# make it all lower case\n",
    "df['Phrase'] = df['Phrase'].str.lower()\n",
    "# remove non-asci characters\n",
    "df.Phrase.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "#df['Phrase'] = df['Phrase'].str.split()\n",
    "\n",
    "df['Tokenized_text'] = df['Phrase'].apply(word_tokenize) \n",
    "\n",
    "df['Sentiment']=df['Sentiment'].astype(int) #convert the star_rating column to int\n",
    "df['NNLabels'] = df['Sentiment'].div(4)\n",
    "\n",
    "df= df[df['Sentiment']!=2]\n",
    "\n",
    "#df['label']=np.where(df['Sentiment']>=4,1,0) #1-Positve,0-Negative\n",
    "# convert to NumPy Array\n",
    "train = df['Phrase'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (61182,) (61182,) Test:  ((15296,), (15296,))\n",
      "Train:  (30591,) (30591,) Test:  ((30591,), (30591,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 0 if x < 2 else 1)\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(df['Phrase'], df['Sentiment'], test_size=0.2, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))\n",
    "X_train,X_valid,Y_train, Y_valid = train_test_split(X_train,Y_train, test_size=0.5, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_valid.shape,Y_valid.shape))\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "tf_x_train = tfidfvectorizer.fit_transform(X_train)\n",
    "tf_x_valid = tfidfvectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.4570247933884298,\n",
       "  'recall': 0.28132267441860465,\n",
       "  'f1-score': 0.34826810616284304,\n",
       "  'support': 13760},\n",
       " '1': {'precision': 0.5529587270014918,\n",
       "  'recall': 0.7267542035529677,\n",
       "  'f1-score': 0.6280550421031013,\n",
       "  'support': 16831},\n",
       " 'accuracy': 0.5263966526102448,\n",
       " 'macro avg': {'precision': 0.5049917601949608,\n",
       "  'recall': 0.5040384389857862,\n",
       "  'f1-score': 0.4881615741329721,\n",
       "  'support': 30591},\n",
       " 'weighted avg': {'precision': 0.5098071161840705,\n",
       "  'recall': 0.5263966526102448,\n",
       "  'f1-score': 0.5022053399509012,\n",
       "  'support': 30591}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf1.predict(tf_x_valid)\n",
    "report=classification_report(Y_valid, preds,output_dict=True)\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "- Interestingly, the rotten tomatoes dataset cross-test isn't great. I imagine this has to do with the rotten tomatoes dataset not being as \"cut and dry\" as the IMDB dataset, that is it has a lot more neutral reviews in it. Even removing all the most \"neutral\" (#2s) that still leaves 1's and 3's which are not super negative or super positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
