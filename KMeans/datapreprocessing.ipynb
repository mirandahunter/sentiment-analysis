{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/wjones/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/r024mm7x74qd70l_5q2qs0hm0000gn/T/ipykernel_2816/2084871368.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Phrase'] = df['Phrase'].str.replace(r'[^\\w\\s]+', '')\n",
      "/var/folders/01/r024mm7x74qd70l_5q2qs0hm0000gn/T/ipykernel_2816/2084871368.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Phrase'] = df['Phrase'].str.replace(r'\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "path = \"RottenTomatoes/DataSet/train.tsv\"\n",
    "df = pd.read_csv(path, sep=\"\\t\") \n",
    "\n",
    "# remove punctuation\n",
    "df['Phrase'] = df['Phrase'].str.replace(r'[^\\w\\s]+', '')\n",
    "# remove numbers\n",
    "df['Phrase'] = df['Phrase'].str.replace(r'\\d+', '')\n",
    "# make it all lower case\n",
    "df['Phrase'] = df['Phrase'].str.lower()\n",
    "# remove non-asci characters\n",
    "df.Phrase.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "#df['Phrase'] = df['Phrase'].str.split()\n",
    "\n",
    "df['Tokenized_text'] = df['Phrase'].apply(word_tokenize) \n",
    "\n",
    "df['Sentiment']=df['Sentiment'].astype(int) #convert the star_rating column to int\n",
    "\n",
    "df= df[df['Sentiment']!=2]\n",
    "\n",
    "#df['label']=np.where(df['Sentiment']>=4,1,0) #1-Positve,0-Negative\n",
    "# convert to NumPy Array\n",
    "train = df['Phrase'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>good for the goose</td>\n",
       "      <td>3</td>\n",
       "      <td>[good, for, the, goose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "      <td>[good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>the gander  some of which occasionally amuses ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, gander, some, of, which, occasionally, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>amuses</td>\n",
       "      <td>3</td>\n",
       "      <td>[amuses]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156047</th>\n",
       "      <td>156048</td>\n",
       "      <td>8544</td>\n",
       "      <td>quietly suggesting the sadness and obsession b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[quietly, suggesting, the, sadness, and, obses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>156052</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>1</td>\n",
       "      <td>[sadness, and, obsession]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156052</th>\n",
       "      <td>156053</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and</td>\n",
       "      <td>1</td>\n",
       "      <td>[sadness, and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76478 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "21            22           1   \n",
       "22            23           1   \n",
       "33            34           1   \n",
       "46            47           1   \n",
       "...          ...         ...   \n",
       "156047    156048        8544   \n",
       "156051    156052        8544   \n",
       "156052    156053        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \\\n",
       "0       a series of escapades demonstrating the adage ...          1   \n",
       "21                                     good for the goose          3   \n",
       "22                                                   good          3   \n",
       "33      the gander  some of which occasionally amuses ...          1   \n",
       "46                                                 amuses          3   \n",
       "...                                                   ...        ...   \n",
       "156047  quietly suggesting the sadness and obsession b...          1   \n",
       "156051                              sadness and obsession          1   \n",
       "156052                                        sadness and          1   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "\n",
       "                                           Tokenized_text  \n",
       "0       [a, series, of, escapades, demonstrating, the,...  \n",
       "21                                [good, for, the, goose]  \n",
       "22                                                 [good]  \n",
       "33      [the, gander, some, of, which, occasionally, a...  \n",
       "46                                               [amuses]  \n",
       "...                                                   ...  \n",
       "156047  [quietly, suggesting, the, sadness, and, obses...  \n",
       "156051                          [sadness, and, obsession]  \n",
       "156052                                     [sadness, and]  \n",
       "156056                      [forced, avuncular, chortles]  \n",
       "156057                              [avuncular, chortles]  \n",
       "\n",
       "[76478 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (61182,) (61182,) Test:  ((15296,), (15296,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(df['Phrase'], df['Sentiment'], test_size=0.2, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (30591,) (30591,) Test:  ((30591,), (30591,))\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,Y_train, Y_valid = train_test_split(X_train,Y_train, test_size=0.5, random_state=30)\n",
    "print(\"Train: \" ,X_train.shape,Y_train.shape,\"Test: \",(X_valid.shape,Y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_wm = countvectorizer.fit_transform(X_train)\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),columns = tfidf_tokens)\n",
    "\n",
    "tf_x_train = tfidfvectorizer.fit_transform(X_train)\n",
    "tf_x_valid = tfidfvectorizer.transform(X_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10630)\t0.23514574481564446\n",
      "  (0, 7444)\t0.23916889825206192\n",
      "  (0, 7221)\t0.25421379442401687\n",
      "  (0, 6165)\t0.4008984640885048\n",
      "  (0, 5899)\t0.3789598395732692\n",
      "  (0, 5736)\t0.36918964565400303\n",
      "  (0, 5692)\t0.4362689286434968\n",
      "  (0, 4627)\t0.2684799894839538\n",
      "  (0, 360)\t0.34617459135447454\n",
      "  (1, 12375)\t1.0\n",
      "  (2, 6216)\t0.8887991477692279\n",
      "  (2, 4618)\t0.4582969287751058\n",
      "  (3, 12335)\t1.0\n",
      "  (4, 4375)\t1.0\n",
      "  (5, 8139)\t0.17403148468268126\n",
      "  (5, 7078)\t0.40076733585757945\n",
      "  (5, 6655)\t0.33872096564200255\n",
      "  (5, 5970)\t0.41179741407057174\n",
      "  (5, 2963)\t0.39614310979854855\n",
      "  (5, 2519)\t0.3813754933436585\n",
      "  (5, 2260)\t0.3542061384747951\n",
      "  (5, 1843)\t0.3113694961792016\n",
      "  (6, 12825)\t0.6149049278448969\n",
      "  (6, 5802)\t0.7886012488653958\n",
      "  (7, 12937)\t0.524967893352863\n",
      "  :\t:\n",
      "  (30587, 6892)\t0.7538647738253904\n",
      "  (30587, 5402)\t0.6570296057143795\n",
      "  (30588, 11639)\t0.3104935305427958\n",
      "  (30588, 11398)\t0.26502101588306703\n",
      "  (30588, 9064)\t0.1970210574025752\n",
      "  (30588, 6878)\t0.29980294080900827\n",
      "  (30588, 6864)\t0.29419488378855974\n",
      "  (30588, 4443)\t0.20950884859028165\n",
      "  (30588, 2757)\t0.33376269465800523\n",
      "  (30588, 2566)\t0.28939094443904123\n",
      "  (30588, 1493)\t0.27504151734761584\n",
      "  (30588, 1237)\t0.2872243664275865\n",
      "  (30588, 1124)\t0.1967365615670604\n",
      "  (30588, 420)\t0.33376269465800523\n",
      "  (30588, 343)\t0.2661217803238319\n",
      "  (30589, 7907)\t0.45658648318961603\n",
      "  (30589, 4464)\t0.6556647920303924\n",
      "  (30589, 1346)\t0.6013588478273856\n",
      "  (30590, 12057)\t0.4363632364824802\n",
      "  (30590, 10042)\t0.31615839628644693\n",
      "  (30590, 8038)\t0.35566839923819354\n",
      "  (30590, 7428)\t0.34416924519724745\n",
      "  (30590, 3772)\t0.4363632364824802\n",
      "  (30590, 3444)\t0.4129898767596481\n",
      "  (30590, 129)\t0.32203261059774785\n"
     ]
    }
   ],
   "source": [
    "print(tf_x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(tf_x_train)\n",
    "preds = kmeans.predict(tf_x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(tf_x_valid[:,0], tf_x_valid[:,1], c=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(Y_valid, preds,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.08965414319292617,\n",
       "  'recall': 0.8440463645943098,\n",
       "  'f1-score': 0.16209106239460372,\n",
       "  'support': 2847},\n",
       " '1': {'precision': 0.352112676056338,\n",
       "  'recall': 0.045816915605241454,\n",
       "  'f1-score': 0.08108327252087894,\n",
       "  'support': 10913},\n",
       " '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0},\n",
       " '3': {'precision': 0.5243619489559165,\n",
       "  'recall': 0.017251908396946566,\n",
       "  'f1-score': 0.033404774222156534,\n",
       "  'support': 13100},\n",
       " '4': {'precision': 0.46048109965635736,\n",
       "  'recall': 0.035915304207987137,\n",
       "  'f1-score': 0.06663351566384883,\n",
       "  'support': 3731},\n",
       " 'accuracy': 0.10666535909254356,\n",
       " 'macro avg': {'precision': 0.2853219735723076,\n",
       "  'recall': 0.188606098560897,\n",
       "  'f1-score': 0.0686425249602976,\n",
       "  'support': 30591},\n",
       " 'weighted avg': {'precision': 0.41466599632615647,\n",
       "  'recall': 0.10666535909254356,\n",
       "  'f1-score': 0.06644265296688108,\n",
       "  'support': 30591}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.4579002079002079,\n",
       "  'recall': 0.30944854232525465,\n",
       "  'f1-score': 0.36931460909662545,\n",
       "  'support': 2847},\n",
       " '1': {'precision': 0.690320874471086,\n",
       "  'recall': 0.7175845322092916,\n",
       "  'f1-score': 0.7036887271420227,\n",
       "  'support': 10913},\n",
       " '3': {'precision': 0.6874407261888633,\n",
       "  'recall': 0.7746564885496183,\n",
       "  'f1-score': 0.7284473476419496,\n",
       "  'support': 13100},\n",
       " '4': {'precision': 0.5048809058961343,\n",
       "  'recall': 0.346555883141249,\n",
       "  'f1-score': 0.41099809281627464,\n",
       "  'support': 3731},\n",
       " 'accuracy': 0.6587885325749403,\n",
       " 'macro avg': {'precision': 0.5851356786140729,\n",
       "  'recall': 0.5370613615563534,\n",
       "  'f1-score': 0.5531121941742181,\n",
       "  'support': 30591},\n",
       " 'weighted avg': {'precision': 0.6448399126529842,\n",
       "  'recall': 0.6587885325749403,\n",
       "  'f1-score': 0.6474743522541285,\n",
       "  'support': 30591}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(tf_x_train,Y_train)\n",
    "y_test_pred=clf.predict(tf_x_valid)\n",
    "\n",
    "report=classification_report(Y_valid, y_test_pred,output_dict=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = tf_x_valid.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 19:50:48.752492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#y_target = to_categorical(train_data['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = to_categorical(df['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76478, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(df['Phrase'], df['Sentiment'],test_size = 0.2,stratify = y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61182/61182 [00:00<00:00, 1019040.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocab :  27\n",
      "Max_length :  265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "unique_words = set()\n",
    "len_max = -1\n",
    "\n",
    "for sent in tqdm(X_train):\n",
    "    unique_words.update(sent)\n",
    "    if(len_max < len(sent)):\n",
    "        len_max = len(sent)\n",
    "\n",
    "print('Words in vocab : ' , len(list(unique_words)))\n",
    "print('Max_length : ' , len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(list(unique_words))\n",
    "embedding_dim = 300\n",
    "max_length = len_max\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size,\n",
    "                      # filters = '#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      oov_token = oov_tok,\n",
    "                      # lower = True,\n",
    "                      char_level = False)\n",
    "\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "# Training\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,\n",
    "                        maxlen = max_length,\n",
    "                        padding = padding_type,\n",
    "                        truncating = trunc_type)\n",
    "\n",
    "# Validation\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val,\n",
    "                      maxlen = max_length,\n",
    "                      padding = padding_type,\n",
    "                      truncating = trunc_type)\n",
    "\n",
    "# Testing\n",
    "X_test = tokenizer.texts_to_sequences(df['Phrase'])\n",
    "X_test = pad_sequences(X_test,\n",
    "                       maxlen = max_length,\n",
    "                       padding = padding_type,\n",
    "                       truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=5, random_state=0)\n",
    "kmeans.fit(X_train)\n",
    "preds = kmeans.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(y_val, preds,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.10354477611940298,\n",
       "  'recall': 0.0785007072135785,\n",
       "  'f1-score': 0.08930008045052293,\n",
       "  'support': 1414},\n",
       " '1': {'precision': 0.3858891288696904,\n",
       "  'recall': 0.09825847846012832,\n",
       "  'f1-score': 0.15663354763296317,\n",
       "  'support': 5455},\n",
       " '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0},\n",
       " '3': {'precision': 0.4600760456273764,\n",
       "  'recall': 0.5695414515639234,\n",
       "  'f1-score': 0.5089897550715787,\n",
       "  'support': 6586},\n",
       " '4': {'precision': 0.11987381703470032,\n",
       "  'recall': 0.10320478001086367,\n",
       "  'f1-score': 0.11091652072387626,\n",
       "  'support': 1841},\n",
       " 'accuracy': 0.2999476987447699,\n",
       " 'macro avg': {'precision': 0.21387675353023403,\n",
       "  'recall': 0.1699010834496988,\n",
       "  'f1-score': 0.1731679807757882,\n",
       "  'support': 15296},\n",
       " 'weighted avg': {'precision': 0.3597140458341907,\n",
       "  'recall': 0.2999476987447699,\n",
       "  'f1-score': 0.29662069545298947,\n",
       "  'support': 15296}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
