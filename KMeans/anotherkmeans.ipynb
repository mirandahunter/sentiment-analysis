{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/wjones/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/wjones/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"RottenTomatoes/DataSet/train.tsv\"\n",
    "df = pd.read_csv(path, sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(df):\n",
    "    \n",
    "    reviews = []\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        # removing non-alphabetical characters \n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \",sent)\n",
    "        \n",
    "        # Now tokenizing the sentence : \n",
    "        words = word_tokenize(text.lower())\n",
    "        \n",
    "        #removing stop words :\n",
    "        new_words = [ ele for ele in words if ele.lower() not in stopwords.words('english') ]\n",
    "        \n",
    "        # Lemmatizing each word to its lemma\n",
    "        lem = WordNetLemmatizer()\n",
    "        lem_words = [lem.lemmatize(i) for i in new_words]\n",
    "        \n",
    "        #finally\n",
    "        reviews.append(lem_words)\n",
    "        \n",
    "    return(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [01:08<00:00, 2286.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_sentences = clean_sentences(df)\n",
    "#test_sentences = clean_sentences()\n",
    "\n",
    "print(len(train_sentences))\n",
    "#print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_target = to_categorical(df['Sentiment'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(df['Phrase'], df['Sentiment'],test_size = 0.2,stratify = y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124848/124848 [00:00<00:00, 1443744.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocab :  80\n",
      "Max_length :  283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "unique_words = set()\n",
    "len_max = -1\n",
    "\n",
    "for sent in tqdm(X_train):\n",
    "    unique_words.update(sent)\n",
    "    if(len_max < len(sent)):\n",
    "        len_max = len(sent)\n",
    "\n",
    "print('Words in vocab : ' , len(list(unique_words)))\n",
    "print('Max_length : ' , len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(list(unique_words))\n",
    "embedding_dim = 300\n",
    "max_length = len_max\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size,\n",
    "                      # filters = '#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      oov_token = oov_tok,\n",
    "                      # lower = True,\n",
    "                      char_level = False)\n",
    "\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "# Training\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,\n",
    "                        maxlen = max_length,\n",
    "                        padding = padding_type,\n",
    "                        truncating = trunc_type)\n",
    "\n",
    "# Validation\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val,\n",
    "                      maxlen = max_length,\n",
    "                      padding = padding_type,\n",
    "                      truncating = trunc_type)\n",
    "\n",
    "# Testing\n",
    "X_test = tokenizer.texts_to_sequences(df['Phrase'])\n",
    "X_test = pad_sequences(X_test,\n",
    "                       maxlen = max_length,\n",
    "                       padding = padding_type,\n",
    "                       truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61182/61182 [00:00<00:00, 1019040.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocab :  27\n",
      "Max_length :  265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=4, random_state=0)\n",
    "kmeans.fit(X_train)\n",
    "preds = kmeans.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(y_val, preds,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.05037593984962406,\n",
       "  'recall': 0.09476661951909476,\n",
       "  'f1-score': 0.06578301423662249,\n",
       "  'support': 1414},\n",
       " '1': {'precision': 0.24616482340349624,\n",
       "  'recall': 0.2529789184234647,\n",
       "  'f1-score': 0.24952535937076212,\n",
       "  'support': 5455},\n",
       " '2': {'precision': 0.4882758620689655,\n",
       "  'recall': 0.08896707715506409,\n",
       "  'f1-score': 0.15051020408163265,\n",
       "  'support': 15916},\n",
       " '3': {'precision': 0.19949117030829094,\n",
       "  'recall': 0.6071970847251746,\n",
       "  'f1-score': 0.300315410033043,\n",
       "  'support': 6586},\n",
       " '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1841},\n",
       " 'accuracy': 0.2219979495066,\n",
       " 'macro avg': {'precision': 0.19686155912607534,\n",
       "  'recall': 0.20878193996455963,\n",
       "  'f1-score': 0.15322679754441207,\n",
       "  'support': 31212},\n",
       " 'weighted avg': {'precision': 0.3363869075661124,\n",
       "  'recall': 0.2219979495066,\n",
       "  'f1-score': 0.1867094616217794,\n",
       "  'support': 31212}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wjones/opt/anaconda3/envs/py4sci/lib/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "report=classification_report(y_val, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.10344827586206896,\n",
       "  'recall': 0.006364922206506365,\n",
       "  'f1-score': 0.011992005329780148,\n",
       "  'support': 1414},\n",
       " '1': {'precision': 0.23849453978159127,\n",
       "  'recall': 0.22419798350137488,\n",
       "  'f1-score': 0.23112538977605593,\n",
       "  'support': 5455},\n",
       " '2': {'precision': 0.5510287560845911,\n",
       "  'recall': 0.8463810002513195,\n",
       "  'f1-score': 0.6674925055124743,\n",
       "  'support': 15916},\n",
       " '3': {'precision': 0.26106696935300794,\n",
       "  'recall': 0.034922563012450655,\n",
       "  'f1-score': 0.061604392661041917,\n",
       "  'support': 6586},\n",
       " '4': {'precision': 0.08819133034379671,\n",
       "  'recall': 0.03204780010863661,\n",
       "  'f1-score': 0.04701195219123506,\n",
       "  'support': 1841},\n",
       " 'accuracy': 0.4803280789439959,\n",
       " 'macro avg': {'precision': 0.2484459742850112,\n",
       "  'recall': 0.2287828538160576,\n",
       "  'f1-score': 0.20384524909411747,\n",
       "  'support': 31212},\n",
       " 'weighted avg': {'precision': 0.38764528251126934,\n",
       "  'recall': 0.4803280789439959,\n",
       "  'f1-score': 0.3970854782952365,\n",
       "  'support': 31212}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
